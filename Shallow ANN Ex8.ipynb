{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "123b75d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "import sklearn.metrics as metric\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ec0c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training=[[1, 1],\n",
    " [1, 0],\n",
    " [0, 1],\n",
    " [0, 0]\n",
    " ]\n",
    "y_training=[1,\n",
    " 1,\n",
    " 1,\n",
    " 0\n",
    " ]\n",
    "X_testing=X_training\n",
    "y_true=y_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7897fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0]\n",
      "acuracy= 1.0\n"
     ]
    }
   ],
   "source": [
    "ptn = Perceptron(max_iter=500) # set the method\n",
    "ptn.fit(X_training, y_training) # training\n",
    "y_pred=ptn.predict(X_testing) # prediction\n",
    "print(y_pred) # show the output\n",
    "accuracy=metric.accuracy_score(y_true, y_pred, normalize=True)\n",
    "print('acuracy=',accuracy) # show accracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef94e48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.] [[2. 2.]]\n"
     ]
    }
   ],
   "source": [
    "print(ptn.intercept_, ptn.coef_) # show the synapsis weights w0, w1, w2, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed64a4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0]\n",
      "acuracy= 1.0\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(1,1), activation='logistic') #set the method\n",
    "mlp.fit(X_training, y_training) # training\n",
    "y_pred=mlp.predict(X_testing) # prediction\n",
    "print(y_pred) # show the output\n",
    "accuracy=metric.accuracy_score(np.array(y_true).flatten(), np.array(y_pred).flatten(),\n",
    "normalize=True)\n",
    "print('acuracy=',accuracy) # show accracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8d0f7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 1), (1, 1), (1, 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[4.09394745],\n",
       "        [4.31844729]]),\n",
       " array([[8.04993388]]),\n",
       " array([[15.02574918]])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print([coef.shape for coef in mlp.coefs_]) # size of synapsis weights\n",
    "mlp.coefs_ # synapsis weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b109c79b",
   "metadata": {},
   "source": [
    "# 1. Bipolar OR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4a39efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1 -1]\n",
      "acuracy= 1.0\n",
      "[ 1  1  1 -1]\n",
      "acuracy= 1.0\n"
     ]
    }
   ],
   "source": [
    "X_training=[[1, 1],\n",
    " [1, -1],\n",
    " [-1, 1],\n",
    " [-1, -1]\n",
    " ]\n",
    "y_training=[1,\n",
    " 1,\n",
    " 1,\n",
    " -1\n",
    " ]\n",
    "X_testing=X_training\n",
    "y_true=y_training \n",
    "ptn = Perceptron(max_iter=500) # set the method\n",
    "ptn.fit(X_training, y_training) # training\n",
    "y_pred=ptn.predict(X_testing) # prediction\n",
    "print(y_pred) # show the output\n",
    "accuracy=metric.accuracy_score(y_true, y_pred, normalize=True)\n",
    "print('acuracy=',accuracy) # show accracy score\n",
    "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(1,1), activation='logistic') #set the method\n",
    "mlp.fit(X_training, y_training) # training\n",
    "y_pred=mlp.predict(X_testing) # prediction\n",
    "print(y_pred) # show the output\n",
    "accuracy=metric.accuracy_score(np.array(y_true).flatten(), np.array(y_pred).flatten(),\n",
    "normalize=True)\n",
    "print('acuracy=',accuracy) # show accracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c5446b",
   "metadata": {},
   "source": [
    "# 2. AND gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01351099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0]\n",
      "acuracy= 1.0\n",
      "[1 0 0 0]\n",
      "acuracy= 1.0\n"
     ]
    }
   ],
   "source": [
    "X_training=[[1, 1],\n",
    " [1, 0],\n",
    " [0, 1],\n",
    " [0, 0]\n",
    " ]\n",
    "y_training=[1,\n",
    " 0,\n",
    " 0,\n",
    " 0\n",
    " ]\n",
    "X_testing=X_training\n",
    "y_true=y_training \n",
    "ptn = Perceptron(max_iter=500) # set the method\n",
    "ptn.fit(X_training, y_training) # training\n",
    "y_pred=ptn.predict(X_testing) # prediction\n",
    "print(y_pred) # show the output\n",
    "accuracy=metric.accuracy_score(y_true, y_pred, normalize=True)\n",
    "print('acuracy=',accuracy) # show accracy score\n",
    "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(1,1), activation='logistic') #set the method\n",
    "mlp.fit(X_training, y_training) # training\n",
    "y_pred=mlp.predict(X_testing) # prediction\n",
    "print(y_pred) # show the output\n",
    "accuracy=metric.accuracy_score(np.array(y_true).flatten(), np.array(y_pred).flatten(),\n",
    "normalize=True)\n",
    "print('acuracy=',accuracy) # show accracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce549380",
   "metadata": {},
   "source": [
    "# 3. Bipolar AND gate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32bb0715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1 -1 -1]\n",
      "acuracy= 1.0\n",
      "[ 1 -1 -1 -1]\n",
      "acuracy= 1.0\n"
     ]
    }
   ],
   "source": [
    "X_training=[[1, 1],\n",
    " [1, -1],\n",
    " [-1, 1],\n",
    " [-1, -1]\n",
    " ]\n",
    "y_training=[1,\n",
    " -1,\n",
    " -1,\n",
    " -1\n",
    " ]\n",
    "X_testing=X_training\n",
    "y_true=y_training \n",
    "ptn = Perceptron(max_iter=500) # set the method\n",
    "ptn.fit(X_training, y_training) # training\n",
    "y_pred=ptn.predict(X_testing) # prediction\n",
    "print(y_pred) # show the output\n",
    "accuracy=metric.accuracy_score(y_true, y_pred, normalize=True)\n",
    "print('acuracy=',accuracy) # show accracy score\n",
    "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(1,1), activation='logistic') #set the method\n",
    "mlp.fit(X_training, y_training) # training\n",
    "y_pred=mlp.predict(X_testing) # prediction\n",
    "print(y_pred) # show the output\n",
    "accuracy=metric.accuracy_score(np.array(y_true).flatten(), np.array(y_pred).flatten(),\n",
    "normalize=True)\n",
    "print('acuracy=',accuracy) # show accracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b64e92",
   "metadata": {},
   "source": [
    "# 4. Two output neurons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50f28fbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (4, 2) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bg/49hdc2yx15zdb796ct2xvzn40000gn/T/ipykernel_57275/1263948090.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mptn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# set the method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mptn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_training\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mptn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_testing\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# show the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         \"\"\"\n\u001b[0;32m--> 729\u001b[0;31m         return self._fit(X, y, alpha=self.alpha, C=1.0,\n\u001b[0m\u001b[1;32m    730\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         X, y = self._validate_data(X, y, accept_sparse='csr',\n\u001b[0m\u001b[1;32m    544\u001b[0m                                    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                                    accept_large_sparse=False)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    881\u001b[0m                         ensure_2d=False, dtype=None)\n\u001b[1;32m    882\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    922\u001b[0m         \u001b[0;34m\"y should be a 1d array, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \"got an array of shape {} instead.\".format(shape))\n",
      "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (4, 2) instead."
     ]
    }
   ],
   "source": [
    "X_training=[[1, 1],\n",
    " [1, 0],\n",
    " [0, 1],\n",
    " [0, 0]\n",
    " ]\n",
    "y_training=[[1, 1],\n",
    " [1, 1],\n",
    " [1, 1],\n",
    " [0, 1]\n",
    " ]\n",
    "X_testing=X_training\n",
    "y_true=y_training \n",
    "ptn = Perceptron(max_iter=500) # set the method\n",
    "ptn.fit(X_training, y_training) # training\n",
    "y_pred=ptn.predict(X_testing) # prediction\n",
    "print(y_pred) # show the output\n",
    "accuracy=metric.accuracy_score(y_true, y_pred, normalize=True)\n",
    "print('acuracy=',accuracy) # show accracy score\n",
    "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(1,1), activation='logistic') #set the method\n",
    "mlp.fit(X_training, y_training) # training\n",
    "y_pred=mlp.predict(X_testing) # prediction\n",
    "print(y_pred) # show the output\n",
    "accuracy=metric.accuracy_score(np.array(y_true).flatten(), np.array(y_pred).flatten(),\n",
    "normalize=True)\n",
    "print('acuracy=',accuracy) # show accracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ee11d9",
   "metadata": {},
   "source": [
    "# y should be a 1d array, got an array of shape (4, 2) instead.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86f4af2",
   "metadata": {},
   "source": [
    "# 5. XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "205eacea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0]\n",
      "acuracy= 0.5\n",
      "[1 0 0 1]\n",
      "acuracy= 1.0\n"
     ]
    }
   ],
   "source": [
    "X_training=[[1, 1],\n",
    " [1, 0],\n",
    " [0, 1],\n",
    " [0, 0]\n",
    " ]\n",
    "y_training=[1,\n",
    " 0,\n",
    " 0,\n",
    " 1\n",
    " ]\n",
    "X_testing=X_training\n",
    "y_true=y_training \n",
    "ptn = Perceptron(max_iter=500) # set the method\n",
    "ptn.fit(X_training, y_training) # training\n",
    "y_pred=ptn.predict(X_testing) # prediction\n",
    "print(y_pred) # show the output\n",
    "accuracy=metric.accuracy_score(y_true, y_pred, normalize=True)\n",
    "print('acuracy=',accuracy) # show accracy score\n",
    "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(3,2), activation='logistic') #set the method\n",
    "mlp.fit(X_training, y_training) # training\n",
    "y_pred=mlp.predict(X_testing) # prediction\n",
    "print(y_pred) # show the output\n",
    "accuracy=metric.accuracy_score(np.array(y_true).flatten(), np.array(y_pred).flatten(),\n",
    "normalize=True)\n",
    "print('acuracy=',accuracy) # show accracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51429b79",
   "metadata": {},
   "source": [
    "# If we add more layers in the hidden layer we will get more acurate result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacdaade",
   "metadata": {},
   "source": [
    "# 6. Neural Network with 3 input and 2 output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b3b7cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]]\n",
      "acuracy= 1.0\n"
     ]
    }
   ],
   "source": [
    "X_training=[[ 1, 1, 0],\n",
    " [ 1, -1, -1],\n",
    " [-1, 1, 1],\n",
    " [-1, -1, 1],\n",
    " [ 0, 1, -1],\n",
    " [ 0, -1, -1],\n",
    " [ 1, 1, 1]\n",
    " ]\n",
    "y_training=[[1, 0],\n",
    " [0, 1],\n",
    " [1, 1],\n",
    " [1, 0],\n",
    " [1, 0],\n",
    " [1, 1],\n",
    " [1, 1]\n",
    " ]\n",
    "X_testing=X_training\n",
    "y_true=y_training \n",
    "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(3,2), activation='logistic') #set the method\n",
    "mlp.fit(X_training, y_training) # training\n",
    "y_pred=mlp.predict(X_testing) # prediction\n",
    "print(y_pred) # show the output\n",
    "accuracy=metric.accuracy_score(np.array(y_true).flatten(), np.array(y_pred).flatten(),\n",
    "normalize=True)\n",
    "print('acuracy=',accuracy) # show accracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce413293",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
